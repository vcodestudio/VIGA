#!/usr/bin/env python3
"""
BlenderBench Runner for AgenticVerifier.

Loads BlenderBench dataset and runs the dual-agent system for 3D scene generation.
"""
import os
import sys
import shutil
import json
import time
import argparse
import subprocess
import asyncio
import signal
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.common import get_model_info

def check_failed_tasks(test_output_dir: str) -> List[Dict]:
    """
    Check for failed tasks in a test output directory.
    A task is considered failed if:
    1. The task directory doesn't exist
    2. The task directory is empty
    3. The task directory doesn't contain generator_thoughts.json
    
    Args:
        test_output_dir: Path to the test output directory
        
    Returns:
        List of failed task configurations
    """
    failed_tasks = []
    test_output_path = Path(test_output_dir)
    
    if not test_output_path.exists():
        print(f"Error: Test output directory does not exist: {test_output_dir}")
        return failed_tasks
    
    print(f"Checking for failed tasks in: {test_output_dir}")
    
    # Look for task directories
    for task_dir in test_output_path.iterdir():
        if not task_dir.is_dir():
            continue
            
        task_name = task_dir.name
        
        # remove '_evaluation' file, it is not a task
        if '_evaluation' in task_name:
            continue
        
        scores_file = task_dir / "scores.json"
        
        # Check if task failed
        failed = False
        failure_reason = ""
        
        if not task_dir.exists():
            failed = True
            failure_reason = "Task directory does not exist"
        elif not any(task_dir.iterdir()):
            failed = True
            failure_reason = "Task directory is empty"
        elif not scores_file.exists():
            failed = True
            failure_reason = "scores.json not found"
        
        if failed:
            print(f"Found failed task: {task_name} - {failure_reason}")
            # Try to reconstruct task config from task name
            # Task name format is typically like "blendshape1", "geometry2", etc.
            task_type = None
            task_id = None
            
            for task_type_name in ['blendshape', 'geometry', 'lighting', 'material', 'placement']:
                if task_name.startswith(task_type_name):
                    task_type = task_type_name
                    task_id = task_name[len(task_type_name):]
                    break
            
            if task_type and task_id:
                failed_tasks.append({
                    "task_name": task_type,
                    "task_id": task_id,
                    "failure_reason": failure_reason
                })
            else:
                print(f"Warning: Could not parse task name: {task_name}")
    
    print(f"Found {len(failed_tasks)} failed tasks")
    return failed_tasks

def load_blendergym_dataset(base_path: str, task_name: str, task_id: Optional[str] = None) -> List[Dict]:
    """
    Load BlenderGym dataset structure.

    Args:
        base_path: Path to BlenderGym dataset root.
        task_name: Name of the task type to load.
        task_id: Optional specific task ID to run.

    Returns:
        List of task configurations.
    """
    tasks = []
    base_path = Path(base_path)
    
    if not base_path.exists():
        print(f"Error: BlenderGym dataset path does not exist: {base_path}")
        return tasks
    
    if task_name == 'all':
        task_list = ['level1', 'level2', 'level3']
    else:
        task_list = [task_name]
        
    # If task_id is not None, only run the task_id
    if task_id is not None:
        task_dirs = [(base_path /  f"{task_name}/{task_id}", task_name + '-' + task_id[-1])]
    # Otherwise, run all tasks in the task_list
    else:
        task_dirs = []
        for task in task_list:
            task_path = base_path / task
            for task_dir in task_path.glob("*"):
                task_name = task + '-' + str(task_dir.name.split('/')[-1][-1])
                task_dirs.append((task_dir, task_name))
    
    for task_dir, task_name in task_dirs:
        # Check for required files
        start_code_path = task_dir / "start.py"
        start_renders_dir = task_dir / "renders" / "start"
        goal_renders_dir = task_dir / "renders" / "goal"
        blender_file = task_dir / "blender_file.blend"
        
        if not start_code_path.exists():
            print(f"Warning: start.py not found in {task_dir}")
            continue
            
        if not goal_renders_dir.exists() or not start_renders_dir.exists():
            print(f"Warning: renders directory not found: {goal_renders_dir}")
            continue
        
        if not blender_file.exists():
            print(f"Warning: blender_file.blend not found in {task_dir}")
            continue
            
        task_name_path = task_dir / "task.txt"
        if os.path.exists(task_name_path):
            task_description = open(task_name_path, 'r').read()
        else:
            task_description = ""
            
        task_config = {
            "task_name": task_name,
            "task_dir": str(task_dir),
            "init_code_path": str(start_code_path),
            "init_image_path": str(start_renders_dir),
            "target_image_path": str(goal_renders_dir),
            "blender_file": str(blender_file),
            "target_description": task_description,
        }
        tasks.append(task_config)
        print(f"Found task: {task_name}")
    
    return tasks

def run_blendergym_task(task_config: Dict, args: argparse.Namespace) -> Tuple[str, bool, str]:
    """
    Run a single BlenderGym task using main.py
    
    Args:
        task_config: Task configuration dictionary
        args: Command line arguments
        
    Returns:
        Tuple of (task_name, success: bool, error_message: str)
    """
    task_name = "/".join(task_config['task_dir'].split('/')[-2:])
    print(f"\n{'='*60}")
    print(f"Running task: {task_name}")
    print(f"{'='*60}")
    
    # Prepare output directories
    output_base = Path(args.output_dir + "/" + task_name)
    
    # Create directories
    output_base.mkdir(parents=True, exist_ok=True)
    
    # copy blender file to output directory
    shutil.copy(task_config["blender_file"], output_base / "blender_file.blend")
    
    # Build main.py command
    cmd = [
        sys.executable, "main.py",
        "--mode", "blenderstudio",
        "--model", args.model,
        "--api-key", get_model_info(args.model)["api_key"],
        "--api-base-url", get_model_info(args.model)["base_url"],
        "--max-rounds", str(args.max_rounds),
        "--memory-length", str(args.memory_length),
        "--task-name", task_config["task_name"],
        "--init-code-path", str(task_config["init_code_path"]),
        "--init-image-path", str(task_config["init_image_path"]),
        "--target-image-path", str(task_config["target_image_path"]),
        "--target-description", str(task_config["target_description"]),
        "--output-dir", str(output_base),
        # Tool servers
        "--generator-tools", args.generator_tools,
        "--verifier-tools", args.verifier_tools,
        # Blender execution parameters (for generator)
        "--blender-command", args.blender_command,
        "--blender-file", str(output_base / "blender_file.blend"),
        "--blender-script", args.blender_script,
        "--gpu-devices", args.gpu_devices,
        "--clear-memory",
        "--num-candidates", str(args.num_candidates),
    ]
    
    if args.no_tools:
        cmd.append("--no-tools")
    
    print(f"Command: {' '.join(cmd)}")
    
    try:
        # Run the command
        result = subprocess.run(cmd)  # no timeout
        print(f"Task completed successfully: {task_name}")
        return (task_name, True, "")
    except subprocess.CalledProcessError as e:
        error_msg = f"Task failed: {task_name}, Error: {e}"
        print(error_msg)
        return (task_name, False, str(e))
    except subprocess.TimeoutExpired:
        error_msg = f"Task timed out: {task_name}"
        print(error_msg)
        return (task_name, False, "Timeout")
    except Exception as e:
        error_msg = f"Task failed with exception: {task_name}, Error: {e}"
        print(error_msg)
        return (task_name, False, str(e))

def run_tasks_parallel(tasks: List[Dict], args: argparse.Namespace, max_workers: int = 10) -> Tuple[int, int, List[Dict]]:
    """
    Run tasks in parallel using ThreadPoolExecutor
    
    Args:
        tasks: List of task configurations
        args: Command line arguments
        max_workers: Maximum number of parallel workers
        
    Returns:
        Tuple of (successful_tasks: int, failed_tasks: int, failed_task_details: List)
    """
    successful_tasks = 0
    failed_tasks = 0
    failed_task_details = []
    
    print(f"\nStarting parallel execution with max {max_workers} workers...")
    print(f"Total tasks: {len(tasks)}")
    
    # Use ThreadPoolExecutor for parallel execution
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # Submit all tasks
        future_to_task = {
            executor.submit(run_blendergym_task, task_config, args): task_config 
            for task_config in tasks
        }
        
        # Process completed tasks
        for future in as_completed(future_to_task):
            task_config = future_to_task[future]
            try:
                task_name, success, error_msg = future.result()
                if success:
                    successful_tasks += 1
                    print(f"{task_name} completed successfully")
                else:
                    failed_tasks += 1
                    failed_task_details.append({
                        "task_name": task_name,
                        "error": error_msg
                    })
                    print(f"{task_name} failed: {error_msg}")
            except Exception as e:
                failed_tasks += 1
                task_name = task_config['task_dir'].split('/')[-1]
                failed_task_details.append({
                    "task_name": task_name,
                    "error": str(e)
                })
                print(f"{task_name} failed with exception: {e}")
    
    return successful_tasks, failed_tasks, failed_task_details

def main() -> None:
    """Entry point for the BlenderBench runner."""
    parser = argparse.ArgumentParser(description="BlenderBench Runner for AgenticVerifier")
    
    # Dataset parameters
    parser.add_argument("--dataset-path", default="data/blenderbench", help="Path to BlenderBench dataset root directory")
    parser.add_argument("--output-dir", default=f"output/blenderbench/{time.strftime('%Y%m%d_%H%M%S')}", help="Output directory for results")
    
    # Task selection
    parser.add_argument("--task", choices=['all', 'level1', 'level2', 'level3'], default='all', help="Specific task to run")
    parser.add_argument("--task-id", default=None, help="Specific task id to run (e.g., '1')")
    parser.add_argument("--test-id", default=None, help="Test ID to check for failed cases and retest them")
    
    # Main.py parameters
    parser.add_argument("--max-rounds", type=int, default=10, help="Maximum number of interaction rounds")
    parser.add_argument("--model", default="gpt-4o", help="OpenAI vision model to use")
    parser.add_argument("--memory-length", type=int, default=24, help="Memory length")
    
    # Blender parameters
    parser.add_argument("--blender-command", default="utils/infinigen/blender/blender", help="Blender command path")
    parser.add_argument("--blender-script", default="data/blenderbench/generator_script.py", help="Blender execution script")
    
    # Tool server scripts (comma-separated)
    parser.add_argument("--generator-tools", default="tools/blender/exec.py,tools/generator_base.py,tools/initialize_plan.py", help="Comma-separated list of generator tool server scripts")
    parser.add_argument("--verifier-tools", default="tools/verifier_base.py,tools/blender/investigator.py", help="Comma-separated list of verifier tool server scripts")
    
    # Parallel execution parameters
    parser.add_argument("--max-workers", type=int, default=8, help="Maximum number of parallel workers")
    parser.add_argument("--sequential", action="store_true", help="Run tasks sequentially instead of in parallel")
    parser.add_argument("--no-tools", action="store_true", help="Use no tools mode")
    parser.add_argument("--num-candidates", type=int, default=1, help="Number of candidates for the model")
    
    available_gpu_devices = os.getenv("CUDA_VISIBLE_DEVICES")
    if available_gpu_devices is None:
        available_gpu_devices = "0,1,2,3,4,5,6,7"
    parser.add_argument("--gpu-devices", default=available_gpu_devices, help="GPU devices for Blender")
    
    args = parser.parse_args()
    
    # Handle test-id logic
    if args.test_id is not None:
        # Check for failed tasks in the specified test output directory
        test_output_dir = f"output/blenderbench/{args.test_id}"
        failed_task_configs = check_failed_tasks(test_output_dir)
        
        if not failed_task_configs:
            print("No failed tasks found to retest!")
            sys.exit(0)
        
        print(f"Found {len(failed_task_configs)} failed tasks to retest")
        
        # Convert failed task configs to task configs for retesting
        tasks = []
        for failed_config in failed_task_configs:
            # Load the specific task from dataset
            retest_tasks = load_blendergym_dataset(args.dataset_path, failed_config["task_name"], failed_config["task_id"])
            if retest_tasks:
                tasks.extend(retest_tasks)
                print(f"Will retest: {failed_config['task_name']}{failed_config['task_id']}")
        
        if not tasks:
            print("No valid tasks found for retesting!")
            sys.exit(1)
    else:
        # Normal execution - load dataset
        print(f"Loading BlenderBench dataset from: {args.dataset_path}")
        tasks = load_blendergym_dataset(args.dataset_path, args.task, args.task_id)
        
        if not tasks:
            print("No valid tasks found in dataset!")
            sys.exit(1)
        
        print(f"Found {len(tasks)} tasks")

        if not tasks:
            print("No tasks match the specified filters!")
            sys.exit(1)
    
    # Create output directory (currently use the original output directory)
    if args.test_id is not None:
        # For retesting, create a new output directory with retest suffix
        args.output_dir = f"output/blenderbench/{args.test_id}"
        print(f"Retesting failed tasks. Use original output directory: {args.output_dir}")
    
    os.makedirs(args.output_dir, exist_ok=True)
    
    # Save args to json
    with open(os.path.join(args.output_dir, "args.json"), "w") as f:
        json.dump(args.__dict__, f, indent=4, ensure_ascii=False)
    
    # Save task list for reference
    with open(os.path.join(args.output_dir, "tasks.json"), "w") as f:
        json.dump(tasks, f, indent=2)
    
    # Run tasks
    start_time = time.time()
    
    if args.sequential:
        # Sequential execution
        print("\nRunning tasks sequentially...")
        successful_tasks = 0
        failed_tasks = 0
        failed_task_details = []
        
        for i, task_config in enumerate(tasks, 1):
            print(f"\nTask {i}/{len(tasks)}")
            task_name, success, error_msg = run_blendergym_task(task_config, args)
            
            if success:
                successful_tasks += 1
            else:
                failed_tasks += 1
                failed_task_details.append({
                    "task_name": task_name,
                    "error": error_msg
                })
    else:
        # Parallel execution
        successful_tasks, failed_tasks, failed_task_details = run_tasks_parallel(
            tasks, args, max_workers=args.max_workers
        )
    
    end_time = time.time()
    execution_time = end_time - start_time
    
    # Summary
    print(f"\n{'='*60}")
    print("EXECUTION SUMMARY")
    print(f"{'='*60}")
    print(f"Total tasks: {len(tasks)}")
    print(f"Successful: {successful_tasks}")
    print(f"Failed: {failed_tasks}")
    print(f"Execution time: {execution_time:.2f} seconds")
    print(f"Output directory: {args.output_dir}")
    
    # Save detailed results
    results = {
        "total_tasks": len(tasks),
        "successful_tasks": successful_tasks,
        "failed_tasks": failed_tasks,
        "execution_time_seconds": execution_time,
        "failed_task_details": failed_task_details,
        "execution_mode": "sequential" if args.sequential else f"parallel_{args.max_workers}_workers"
    }
    
    with open(os.path.join(args.output_dir, "execution_results.json"), "w") as f:
        json.dump(results, f, indent=2)
    
    if successful_tasks > 0:
        print(f"\nResults saved to: {args.output_dir}")
        print("Check individual task directories for renders and thought processes.")
    
    if failed_tasks > 0:
        print(f"\nFailed tasks details saved to: {os.path.join(args.output_dir, 'execution_results.json')}")

if __name__ == "__main__":
    main()
