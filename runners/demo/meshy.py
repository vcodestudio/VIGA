# ======================
# Meshy APIï¼ˆä»scene.pyè¿ç§»ï¼‰
# ======================

import os
import json
import time
import base64
import requests
import logging
import re
import tempfile
import shutil
import zipfile
import cv2
import numpy as np
from typing import Optional, Tuple
from pathlib import Path

# å°è¯•å¯¼å…¥Blender
try:
    import bpy
except ImportError:
    bpy = None

# å°è¯•å¯¼å…¥OpenAI
try:
    from openai import OpenAI
except ImportError:
    OpenAI = None

_HAS_GDINOSAM = True
try:
    import torch
    import torchvision
    from PIL import Image
    from groundingdino.util.inference import load_model, predict
    from groundingdino.util import box_ops
    # SAM v1
    from segment_anything import sam_model_registry, SamPredictor
except Exception as _e:
    _HAS_GDINOSAM = False
    # logging.warning(f"Grounded-SAM backend not available: {_e}")
    
_HAS_YOLO = True
try:
    from ultralytics import YOLO
except Exception as _e:
    _HAS_YOLO = False
    # logging.warning(f"YOLO backend not available: {_e}")

class MeshyAPI:
    """Meshy API å®¢æˆ·ç«¯ï¼šText-to-3D ç”Ÿæˆ + è½®è¯¢ + ä¸‹è½½"""
    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("MESHY_API_KEY")
        if not self.api_key:
            raise ValueError("Meshy API key is required. Set MESHY_API_KEY environment variable or pass api_key parameter.")
        self.base_url = "https://api.meshy.ai"
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
        }

    def create_text_to_3d_preview(self, prompt: str, **kwargs) -> str:
        """
        åˆ›å»º Text-to-3D é¢„è§ˆä»»åŠ¡ï¼ˆæ— è´´å›¾ï¼‰
        Returns: task_id (str)
        """
        url = f"{self.base_url}/openapi/v2/text-to-3d"
        payload = {
            "mode": "preview",
            "prompt": prompt[:600],
        }
        payload.update(kwargs or {})
        resp = requests.post(url, headers=self.headers, data=json.dumps(payload))
        resp.raise_for_status()
        data = resp.json()
        # æœ‰çš„ç¯å¢ƒè¿”å› {"result": "<id>"}ï¼Œæœ‰çš„è¿”å› {"id": "<id>"}
        return data.get("result") or data.get("id")

    def poll_text_to_3d(self, task_id: str, interval_sec: float = 5.0, timeout_sec: int = 1800) -> dict:
        """
        è½®è¯¢ Text-to-3D ä»»åŠ¡ç›´åˆ°ç»“æŸ
        Returns: ä»»åŠ¡ JSONï¼ˆåŒ…å« status / model_urls ç­‰ï¼‰
        """
        import time
        url = f"{self.base_url}/openapi/v2/text-to-3d/{task_id}"
        deadline = time.time() + timeout_sec
        while True:
            r = requests.get(url, headers=self.headers)
            r.raise_for_status()
            js = r.json()
            status = js.get("status")
            if status in ("SUCCEEDED", "FAILED", "CANCELED"):
                return js
            if time.time() > deadline:
                raise TimeoutError(f"Meshy task {task_id} polling timeout")
            time.sleep(interval_sec)

    def create_text_to_3d_refine(self, preview_task_id: str, **kwargs) -> str:
        """
        åŸºäº preview å‘èµ· refine è´´å›¾ä»»åŠ¡
        Returns: refine_task_id (str)
        """
        url = f"{self.base_url}/openapi/v2/text-to-3d"
        payload = {
            "mode": "refine",
            "preview_task_id": preview_task_id,
        }
        payload.update(kwargs or {})
        resp = requests.post(url, headers=self.headers, data=json.dumps(payload))
        resp.raise_for_status()
        data = resp.json()
        return data.get("result") or data.get("id")

    def download_model_url(self, file_url: str, output_path: str) -> None:
        """
        ä» model_urls çš„ç›´é“¾ä¸‹è½½æ–‡ä»¶åˆ°æœ¬åœ°
        """
        r = requests.get(file_url, stream=True)
        r.raise_for_status()
        with open(output_path, "wb") as f:
            for chunk in r.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)

    def create_image_to_3d_preview(self, image_path: str, prompt: str = None, **kwargs) -> str:
        """
        åˆ›å»º Image-to-3D é¢„è§ˆä»»åŠ¡ï¼ˆæ— è´´å›¾ï¼‰
        
        Args:
            image_path: è¾“å…¥å›¾ç‰‡è·¯å¾„
            prompt: å¯é€‰çš„æ–‡æœ¬æç¤º
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns: task_id (str)
        """
        url = f"{self.base_url}/openapi/v1/image-to-3d"
        
        # å‡†å¤‡æ–‡ä»¶ä¸Šä¼ 
        with open(image_path, 'rb') as f:
            # å°†imageè½¬ä¸ºbase64æ ¼å¼
            image_base64 = base64.b64encode(f.read()).decode('utf-8')
            files = {
                'image_url': f"data:image/jpeg;base64,{image_base64}",
                'enable_pbr': True
            }
            
            # å‘é€è¯·æ±‚ï¼ˆæ³¨æ„ï¼šè¿™é‡Œä¸ä½¿ç”¨JSON headersï¼Œå› ä¸ºè¦ä¸Šä¼ æ–‡ä»¶ï¼‰
            headers = {
                "Authorization": f"Bearer {self.api_key}"
            }
            
            resp = requests.post(url, headers=headers, json=files)
            resp.raise_for_status()
            data = resp.json()
            return data.get("result") or data.get("id")

    def create_image_to_3d_refine(self, preview_task_id: str, **kwargs) -> str:
        """
        åŸºäº preview å‘èµ· refine è´´å›¾ä»»åŠ¡ï¼ˆImage-to-3Dï¼‰
        Returns: refine_task_id (str)
        """
        url = f"{self.base_url}/openapi/v1/image-to-3d"
        payload = {
            "mode": "refine",
            "preview_task_id": preview_task_id,
        }
        payload.update(kwargs or {})
        resp = requests.post(url, headers=self.headers, data=json.dumps(payload))
        resp.raise_for_status()
        data = resp.json()
        return data.get("result") or data.get("id")

    def poll_image_to_3d(self, task_id: str, interval_sec: float = 5.0, timeout_sec: int = 1800) -> dict:
        """
        è½®è¯¢ Image-to-3D ä»»åŠ¡ç›´åˆ°ç»“æŸ
        Returns: ä»»åŠ¡ JSONï¼ˆåŒ…å« status / model_urls ç­‰ï¼‰
        """
        import time
        url = f"{self.base_url}/openapi/v1/image-to-3d/{task_id}"
        deadline = time.time() + timeout_sec
        while True:
            r = requests.get(url, headers=self.headers)
            r.raise_for_status()
            js = r.json()
            status = js.get("status")
            if status in ("SUCCEEDED", "FAILED", "CANCELED"):
                return js
            if time.time() > deadline:
                raise TimeoutError(f"Meshy Image-to-3D task {task_id} polling timeout")
            time.sleep(interval_sec)


# ======================
# å›¾ç‰‡æˆªå–å·¥å…·
# ======================

class ImageCropper:
    """å›¾ç‰‡æˆªå–å·¥å…·ï¼Œæ”¯æŒåŸºäºæ–‡æœ¬æè¿°çš„æ™ºèƒ½æˆªå–ï¼ˆGrounding DINO + SAM / YOLO / OpenAI å…œåº•ï¼‰"""

    def __init__(self):
        self.temp_dir = None
        # OpenAI clientï¼ˆä»…åœ¨ openai å…œåº•æ—¶ç”¨ï¼‰
        self._client = None

        # åç«¯é€‰æ‹©ï¼šgrounded_sam / yolo / openai
        self._backend = os.getenv("DETECT_BACKEND", "grounded_sam").lower()

        # Grounded-SAM ç›¸å…³å¥æŸ„ï¼ˆæƒ°æ€§åŠ è½½ï¼‰
        self._gdino_model = None
        self._sam_predictor = None
        self._gdino_device = os.getenv("DET_DEVICE", "cuda" if self._torch_has_cuda() else "cpu")
        self._gdino_repo = os.getenv("GDINO_REPO", "models/IDEA-Research/grounding-dino-base")
        self._sam_type = os.getenv("SAM_TYPE", "vit_h")  # vit_h/vit_l/vit_b
        self._sam_repo = os.getenv("SAM_REPO", "models/facebook/sam-vit-huge")

        # YOLO ç›¸å…³ï¼ˆæƒ°æ€§åŠ è½½ï¼‰
        self._yolo = None
        self._yolo_model = os.getenv("YOLO_MODEL", "models/yolov8x.pt")  # æœ¬åœ°æˆ–auto-download

    # ---------------------------
    # OpenAIï¼ˆå…œåº•ï¼‰å®¢æˆ·ç«¯ï¼ˆæ¥å£ä¿ç•™ï¼‰
    # ---------------------------
    def _get_openai_client(self) -> OpenAI:
        """Initialize and cache the OpenAI client using environment variables."""
        if self._client is None:
            if OpenAI is None:
                raise RuntimeError("openai package not installed")
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                raise RuntimeError("OPENAI_API_KEY not set; required for VLM-based cropping")
            base_url = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
            self._client = OpenAI(api_key=api_key, base_url=base_url)
        return self._client

    # ---------------------------
    # å·¥å…·å‡½æ•°
    # ---------------------------
    def _torch_has_cuda(self) -> bool:
        try:
            import torch
            return torch.cuda.is_available()
        except Exception:
            return False

    def _encode_image_as_data_url(self, image_path: str) -> str:
        with open(image_path, "rb") as f:
            b64 = base64.b64encode(f.read()).decode("utf-8")
        # ç”¨ jpg æ›´é€šç”¨ï¼›è‹¥éœ€ä¸¥æ ¼ pngï¼Œå¯æ”¹å› png
        return f"data:image/jpeg;base64,{b64}"

    # ---------------------------
    # åç«¯ï¼šGrounded-SAM
    # ---------------------------
    def _lazy_init_grounded_sam(self):
        if self._gdino_model is None or self._sam_predictor is None:
            if not _HAS_GDINOSAM:
                raise RuntimeError("Grounding DINO + SAM backend not available")
            # åŠ è½½ GroundingDINO
            self._gdino_model = load_model(model_checkpoint_path=self._gdino_repo, device=self._gdino_device)
            # åŠ è½½ SAM
            if self._sam_type == "vit_h":
                sam_type_key = "vit_h"
            elif self._sam_type == "vit_l":
                sam_type_key = "vit_l"
                self._sam_repo = "models/facebook/sam-vit-large"
            else:
                sam_type_key = "vit_b"
                self._sam_repo = "models/facebook/sam-vit-base"

            sam = sam_model_registry[sam_type_key](checkpoint=None)  # ä¼šä» repo è‡ªåŠ¨æ‹‰å–æƒé‡
            # æ‰‹åŠ¨åŠ è½½æƒé‡ï¼ˆsegment-anything åº“ä¼šè‡ªåŠ¨å¤„ç†ä¸‹è½½ç¼“å­˜ï¼‰
            # è¿™é‡Œé€šè¿‡ from_pretrained è·¯å¾„åŠ è½½æ›´çœå¿ƒï¼Œä½†å®˜æ–¹APIæ˜¯æ³¨å†Œè¡¨+checkpointï¼Œæœ¬å®ç°é‡‡ç”¨çº¯æ³¨å†Œè¡¨+è‡ªåŠ¨æƒé‡
            # è‹¥ä½ æœ¬åœ°å·²æœ‰ ckptï¼Œå¯ç”¨ sam.load_state_dict(torch.load('/path/to/sam_vit_h.pth'))
            self._sam_predictor = SamPredictor(sam.to(self._gdino_device))

    def _grounded_sam_bbox(self, image_path: str, description: str) -> Optional[Tuple[int, int, int, int]]:
        """
        ç”¨ GroundingDINO æ ¹æ®æ–‡æœ¬æ‰¾æ¡†ï¼Œå†ç”¨ SAM ç»†åŒ–æ©è†œ -> å–æœ€å°å¤–æ¥çŸ©å½¢ä¸º bbox
        è¿”å› (x, y, w, h)ï¼ˆåƒç´ ï¼‰
        """
        self._lazy_init_grounded_sam()

        image_pil = Image.open(image_path).convert("RGB")
        image_np = np.array(image_pil)

        # 1) DINO æ–‡æœ¬æ£€ç´¢æ£€æµ‹ï¼šè¿”å› xyxy + logits
        #   box_threshold æ§åˆ¶å€™é€‰æ¡†ï¼Œtext_threshold æ§åˆ¶æ–‡æœ¬åŒ¹é…
        #   è‹¥ä½ å¸Œæœ›æ›´â€œä¸¥æ ¼â€ï¼Œå¯ä»¥æŠŠ box_threshold è°ƒå¤§ï¼ˆå¦‚ 0.35~0.5ï¼‰
        boxes, logits, phrases = predict(
            model=self._gdino_model,
            image=image_pil,
            caption=description,
            box_threshold=float(os.getenv("GDINO_BOX_THRESH", "0.25")),
            text_threshold=float(os.getenv("GDINO_TEXT_THRESH", "0.25")),
            device=self._gdino_device
        )
        if boxes is None or len(boxes) == 0:
            return None

        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„ä¸€ä¸ªæ¡†
        best_idx = int(np.argmax(logits))
        # GroundingDINO è¿”å›çš„æ˜¯ç›¸å¯¹åæ ‡ï¼ˆ0~1ï¼‰ï¼Œè½¬æˆåƒç´  xyxy
        H, W = image_np.shape[:2]
        box_xyxy = boxes[best_idx]  # tensor [x_center, y_center, w, h] or xyxy? ä¾APIè€Œå®š
        # groundingdino.util.inference.predict è¿”å›çš„æ˜¯ xyxy çš„ 0~1 å½’ä¸€åŒ–åæ ‡ï¼ˆå½“å‰ç‰ˆæœ¬ï¼‰
        # è‹¥é‡åˆ°è€ç‰ˆæœ¬è¿”å› cxcywhï¼Œå¯æ”¹ç”¨ box_ops.box_cxcywh_to_xyxy
        if box_xyxy.shape[-1] == 4 and float(box_xyxy[2]) <= 1.0 and float(box_xyxy[3]) <= 1.0:
            # å½’ä¸€åŒ– xyxy -> åƒç´ 
            x1 = int(box_xyxy[0] * W)
            y1 = int(box_xyxy[1] * H)
            x2 = int(box_xyxy[2] * W)
            y2 = int(box_xyxy[3] * H)
        else:
            # å…¼å®¹ï¼šå¦‚æœæ‹¿åˆ° cxcywhï¼Œåˆ™å…ˆè½¬ xyxy
            if hasattr(box_ops, "box_cxcywh_to_xyxy"):
                xyxy = box_ops.box_cxcywh_to_xyxy(box_xyxy.unsqueeze(0)).squeeze(0)
                x1 = int(xyxy[0].item())
                y1 = int(xyxy[1].item())
                x2 = int(xyxy[2].item())
                y2 = int(xyxy[3].item())
            else:
                # é€€è€Œæ±‚å…¶æ¬¡ï¼šç›´æ¥å½“ xyxy åƒç´ 
                x1, y1, x2, y2 = [int(v) for v in box_xyxy.tolist()]

        x1, y1 = max(0, x1), max(0, y1)
        x2, y2 = min(W - 1, x2), min(H - 1, y2)
        if x2 <= x1 or y2 <= y1:
            return None

        # 2) SAM ç»†åŒ–æ©è†œï¼Œç„¶åå†ä»æ©è†œå–æ›´ç´§çš„ bboxï¼ˆæ›´è´´è¾¹ï¼‰
        self._sam_predictor.set_image(image_np)
        # SAM æ”¯æŒä»¥ bbox ä½œä¸º prompt
        mask, _, _ = self._sam_predictor.predict(
            box=np.array([x1, y1, x2, y2]),
            multimask_output=False
        )
        if mask is None or mask.shape[0] == 0:
            # æ²¡æ©è†œå°±è¿”å› dino åŸæ¡†
            return (x1, y1, x2 - x1, y2 - y1)

        mask_bin = (mask[0] > 0) if mask.ndim == 3 else (mask > 0)
        ys, xs = np.where(mask_bin)
        if len(xs) == 0 or len(ys) == 0:
            return (x1, y1, x2 - x1, y2 - y1)

        tight_x1, tight_y1 = int(xs.min()), int(ys.min())
        tight_x2, tight_y2 = int(xs.max()), int(ys.max())
        return (tight_x1, tight_y1, max(1, tight_x2 - tight_x1 + 1), max(1, tight_y2 - tight_y1 + 1))

    # ---------------------------
    # åç«¯ï¼šYOLOï¼ˆç±»ååŒ¹é…ï¼‰
    # ---------------------------
    def _lazy_init_yolo(self):
        if self._yolo is None:
            if not _HAS_YOLO:
                raise RuntimeError("YOLO backend not available")
            self._yolo = YOLO(self._yolo_model)

    def _yolo_bbox(self, image_path: str, description: str) -> Optional[Tuple[int, int, int, int]]:
        """
        ç”¨ YOLO åšç±»åˆ«æ£€æµ‹ï¼›é€šè¿‡ç®€å•çš„åŒä¹‰è¯è¡¨ matching é€‰å‡ºæœ€ç›¸å…³ç±»åˆ«çš„æœ€é«˜åˆ†æ¡†ã€‚
        è¿”å› (x, y, w, h)
        """
        self._lazy_init_yolo()
        res = self._yolo(image_path)[0]
        if res is None or res.boxes is None or len(res.boxes) == 0:
            return None

        # æ„é€ åŒä¹‰è¯æ˜ å°„ï¼ˆå¯æ ¹æ®ä½ çš„ä»»åŠ¡æ‰©å±•ï¼‰
        synonyms = {
            'person': ['human', 'people', 'man', 'woman', 'girl', 'boy', 'child'],
            'car': ['vehicle', 'automobile', 'auto', 'sedan', 'coupe', 'suv'],
            'dog': ['puppy', 'canine'],
            'cat': ['kitten', 'feline'],
            'chair': ['seat', 'stool', 'armchair'],
            'table': ['desk', 'surface'],
            'bottle': ['drink', 'water bottle'],
        }
        desc = description.lower()

        def _match(cls_name: str) -> bool:
            cls = cls_name.lower()
            if cls in desc or desc in cls:
                return True
            for k, vs in synonyms.items():
                if cls == k and any(v in desc for v in vs):
                    return True
                if any(v == cls for v in vs) and k in desc:
                    return True
            return False

        best = None
        for b in res.boxes:
            cls_idx = int(b.cls.item())
            cls_name = res.names.get(cls_idx, str(cls_idx))
            conf = float(b.conf.item())
            x1, y1, x2, y2 = [int(v) for v in b.xyxy[0].tolist()]
            if _match(cls_name):
                if (best is None) or (conf > best[0]):
                    best = (conf, x1, y1, x2, y2)

        # è‹¥æ²¡æœ‰åŒ¹é…ä¸Šç±»åˆ«ï¼Œåˆ™æ‹¿æœ€é«˜åˆ†æ¡†å…œåº•
        if best is None:
            if len(res.boxes) == 0:
                return None
            b = max(res.boxes, key=lambda bb: float(bb.conf.item()))
            x1, y1, x2, y2 = [int(v) for v in b.xyxy[0].tolist()]
            return (x1, y1, max(1, x2 - x1), max(1, y2 - y1))

        _, x1, y1, x2, y2 = best
        return (x1, y1, max(1, x2 - x1), max(1, y2 - y1))

    # ---------------------------
    # åç«¯ï¼šOpenAIï¼ˆä¿æŒä½ åŸé€»è¾‘ä½œä¸ºæœ€åå…œåº•ï¼‰
    # ---------------------------
    def _openai_bbox(self, image_path: str, description: str, model: str = None, temperature: float = 0.0):
        """ä¿ç•™ä½ åŸæœ‰çš„ OpenAI æŸ¥è¯¢ï¼ˆä»…å½“å…¶å®ƒåç«¯ä¸å¯ç”¨æ—¶ï¼‰"""
        client = self._get_openai_client()
        model_name = model or os.getenv("VISION_MODEL", "gpt-4o")
        data_url = self._encode_image_as_data_url(image_path)

        system_prompt = (
            "Given an input image and a target description, respond ONLY with a JSON object "
            "with keys x, y, w, h (integers, pixel coordinates, origin at top-left). "
            "If the target is not present, respond with {\"x\": -1, \"y\": -1, \"w\": 0, \"h\": 0}."
        )
        user_text = f"Target description: {description}\nReturn strictly JSON with keys x,y,w,h."

        resp = client.chat.completions.create(
            model=model_name,
            temperature=temperature,
            messages=[
                {"role": "system", "content": system_prompt},
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": user_text},
                        {"type": "image_url", "image_url": {"url": data_url}},
                    ],
                },
            ],
        )

        content = resp.choices[0].message.content if resp.choices else ""
        if not content:
            return None

        def _extract_json(text: str) -> Optional[dict]:
            try:
                return json.loads(text)
            except Exception:
                pass
            start = text.find("{")
            end = text.rfind("}")
            if start != -1 and end != -1 and end > start:
                try:
                    return json.loads(text[start:end + 1])
                except Exception:
                    return None
            return None

        js = _extract_json(content)
        if not js:
            return None
        x = int(js.get("x", -1))
        y = int(js.get("y", -1))
        w = int(js.get("w", 0))
        h = int(js.get("h", 0))
        if x < 0 or y < 0 or w <= 0 or h <= 0:
            return None
        return (x, y, w, h)

    # ---------------------------
    # ç»Ÿä¸€æ¥å£ï¼šè¯¢é—® bboxï¼ˆç­¾åä¿ç•™ï¼‰
    # ---------------------------
    def _ask_vlm_for_bbox(self, image_path: str, description: str, model: str = None, temperature: float = 0.0) -> Optional[tuple]:
        """
        è¿”å› (x, y, w, h) æˆ– Noneï¼ˆæ‰¾ä¸åˆ°ï¼‰
        ä¼˜å…ˆ grounded_sam -> å¤±è´¥ç”¨ yolo -> å¤±è´¥å†ç”¨ openai
        """
        backend_order = []
        # ç”¨æˆ·æ˜ç¡®æŒ‡å®š backendï¼Ÿ
        b = self._backend
        if b == "grounded_sam":
            backend_order = ["grounded_sam", "yolo", "openai"]
        elif b == "yolo":
            backend_order = ["yolo", "grounded_sam", "openai"]
        else:
            backend_order = ["grounded_sam", "yolo", "openai"]

        last_err = None
        for be in backend_order:
            try:
                if be == "grounded_sam" and _HAS_GDINOSAM:
                    bbox = self._grounded_sam_bbox(image_path, description)
                    if bbox:
                        return bbox
                elif be == "yolo" and _HAS_YOLO:
                    bbox = self._yolo_bbox(image_path, description)
                    if bbox:
                        return bbox
                elif be == "openai":
                    bbox = self._openai_bbox(image_path, description, model=model, temperature=temperature)
                    if bbox:
                        return bbox
            except Exception as e:
                last_err = e
                logging.warning(f"[{be}] backend failed: {e}")
                continue

        if last_err:
            logging.error(f"All backends failed; last error: {last_err}")
        return None

    # ---------------------------
    # å¯¹å¤–ï¼šè£å‰ªï¼ˆç­¾åä¸è¿”å›ç»“æ„ä¿ç•™ï¼‰
    # ---------------------------
    def crop_image_by_text(self, image_path: str, description: str, output_path: str = None,
                           confidence_threshold: float = 0.5, padding: int = 20) -> dict:
        """
        æ ¹æ®æ–‡æœ¬æè¿°ä»å›¾ç‰‡ä¸­æˆªå–ç›¸å…³åŒºåŸŸï¼ˆé€šè¿‡ Grounded-SAM/YOLO/OpenAI è·å– bbox åè£å‰ªï¼‰
        è¿”å›ç»“æ„ä¸åŸç‰ˆæœ¬ä¸€è‡´
        """
        try:
            if not os.path.exists(image_path):
                return {"status": "error", "error": f"Image file not found: {image_path}"}

            image = cv2.imread(image_path)
            if image is None:
                return {"status": "error", "error": f"Failed to load image: {image_path}"}

            bbox = self._ask_vlm_for_bbox(image_path, description)
            if not bbox:
                return {"status": "error", "error": f"No valid bbox for '{description}' from any backend"}

            x, y, w, h = bbox
            height, width = image.shape[:2]
            x1 = max(0, x - padding)
            y1 = max(0, y - padding)
            x2 = min(width, x + w + padding)
            y2 = min(height, y + h + padding)

            if x2 <= x1 or y2 <= y1:
                return {"status": "error", "error": "Computed bbox is invalid after padding"}

            cropped_image = image[y1:y2, x1:x2]

            if output_path is None:
                base_name = os.path.splitext(os.path.basename(image_path))[0]
                output_dir = os.path.dirname(image_path)
                safe_desc = re.sub(r"[^a-zA-Z0-9_\-]+", "_", description.strip())[:40]
                output_path = os.path.join(output_dir, f"{base_name}_cropped_{safe_desc}.jpg")

            ok = cv2.imwrite(output_path, cropped_image)
            if not ok:
                return {"status": "error", "error": f"Failed to write output to: {output_path}"}

            return {
                "status": "success",
                "message": f"Successfully cropped image based on '{description}'",
                "input_image": image_path,
                "output_image": output_path,
                "detected_object": {
                    "description": description,
                    "confidence": None,          # æœ¬å®ç°ä¸ç»Ÿä¸€è¿”å›ç½®ä¿¡åº¦ï¼Œè‹¥éœ€è¦å¯åœ¨å„åç«¯å¡«å……
                    "bbox": [x1, y1, x2 - x1, y2 - y1],
                    "original_bbox": [x, y, w, h]
                },
                "crop_info": {
                    "original_size": [image.shape[1], image.shape[0]],
                    "cropped_size": [x2 - x1, y2 - y1],
                    "padding": padding,
                    "backend": self._backend
                }
            }

        except Exception as e:
            logging.error(f"Failed to crop image: {e}")
            return {"status": "error", "error": str(e)}

    # ---------------------------
    # ä¸‹é¢ä¸¤ä¸ªä¿æŒåŸæ ·ï¼ˆå…¼å®¹ï¼‰
    # ---------------------------
    def _detect_objects(self, image, description: str, confidence_threshold: float) -> list:
        logging.warning("_detect_objects is deprecated; use unified backends instead")
        return []

    def _is_description_match(self, class_name: str, description: str) -> bool:
        description_lower = description.lower()
        class_name_lower = class_name.lower()
        if class_name_lower in description_lower or description_lower in class_name_lower:
            return True
        synonyms = {
            'person': ['human', 'people', 'man', 'woman', 'child'],
            'car': ['vehicle', 'automobile', 'auto'],
            'dog': ['puppy', 'canine'],
            'cat': ['kitten', 'feline'],
            'bird': ['flying', 'winged'],
            'tree': ['plant', 'vegetation'],
            'building': ['house', 'structure', 'architecture'],
            'chair': ['seat', 'furniture'],
            'table': ['desk', 'surface'],
            'book': ['text', 'reading', 'literature']
        }
        for key, values in synonyms.items():
            if class_name_lower == key and any(v in description_lower for v in values):
                return True
            if any(v == class_name_lower for v in values) and key in description_lower:
                return True
        return False

    def _fallback_detection(self, image, description: str) -> list:
        height, width = image.shape[:2]
        mock_detections = []
        if 'person' in description.lower() or 'human' in description.lower():
            mock_detections.append({'class': 'person', 'confidence': 0.8, 'bbox': [width//4, height//4, width//2, height//2]})
        elif 'car' in description.lower() or 'vehicle' in description.lower():
            mock_detections.append({'class': 'car', 'confidence': 0.7, 'bbox': [width//6, height//3, width//3, height//3]})
        elif any(k in description.lower() for k in ['animal', 'dog', 'cat']):
            mock_detections.append({'class': 'animal', 'confidence': 0.6, 'bbox': [width//3, height//3, width//4, height//4]})
        return mock_detections


class AssetImporter:
    """3Dèµ„äº§å¯¼å…¥å™¨ï¼Œæ”¯æŒå¤šç§æ ¼å¼"""
    def __init__(self, blender_path: str):
        self.blender_path = blender_path

    def import_asset(self, asset_path: str, location: tuple = (0, 0, 0), scale: float = 1.0) -> str:
        """å¯¼å…¥3Dèµ„äº§åˆ°Blenderåœºæ™¯"""
        try:
            # ç¡®ä¿æ–‡ä»¶å­˜åœ¨
            if not os.path.exists(asset_path):
                raise FileNotFoundError(f"Asset file not found: {asset_path}")

            # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©å¯¼å…¥æ–¹æ³•
            ext = os.path.splitext(asset_path)[1].lower()

            if ext in ['.fbx', '.obj', '.gltf', '.glb', '.dae', '.3ds', '.blend']:
                # ä½¿ç”¨Blenderçš„å¯¼å…¥æ“ä½œç¬¦
                if ext == '.fbx':
                    bpy.ops.import_scene.fbx(filepath=asset_path)
                elif ext == '.obj':
                    bpy.ops.import_scene.obj(filepath=asset_path)
                elif ext in ['.gltf', '.glb']:
                    bpy.ops.import_scene.gltf(filepath=asset_path)
                elif ext == '.dae':
                    bpy.ops.wm.collada_import(filepath=asset_path)
                elif ext == '.3ds':
                    bpy.ops.import_scene.autodesk_3ds(filepath=asset_path)
                elif ext == '.blend':
                    # é™„æ³¨ï¼šappend éœ€è¦ directory + filenameï¼ˆæŒ‡å‘ .blend å†…éƒ¨è·¯å¾„ï¼‰
                    # è¿™é‡Œä¿ç•™å ä½ï¼Œä»¥é˜²æœªæ¥ç¡®å®éœ€è¦ .blend çš„ append
                    bpy.ops.wm.append(filepath=asset_path)

                # è·å–å¯¼å…¥çš„å¯¹è±¡
                imported_objects = [obj for obj in bpy.context.selected_objects]
                if not imported_objects:
                    raise RuntimeError("No objects were imported")

                # è®¾ç½®ä½ç½®å’Œç¼©æ”¾
                for obj in imported_objects:
                    obj.location = location
                    obj.scale = (scale, scale, scale)

                # è¿”å›å¯¼å…¥çš„å¯¹è±¡åç§°
                return imported_objects[0].name
            else:
                raise ValueError(f"Unsupported file format: {ext}")

        except Exception as e:
            logging.error(f"Failed to import asset: {e}")
            raise

    def extract_zip_asset(self, zip_path: str, extract_dir: str) -> str:
        """ä»ZIPæ–‡ä»¶ä¸­æå–3Dèµ„äº§"""
        try:
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                # æŸ¥æ‰¾3Dæ–‡ä»¶
                asset_files = []
                for file_info in zip_ref.filelist:
                    filename = file_info.filename
                    ext = os.path.splitext(filename)[1].lower()
                    if ext in ['.fbx', '.obj', '.gltf', '.glb', '.dae', '.3ds', '.blend']:
                        asset_files.append(filename)

                if not asset_files:
                    raise ValueError("No supported 3D files found in ZIP")

                # æå–ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„3Dæ–‡ä»¶
                asset_file = asset_files[0]
                zip_ref.extract(asset_file, extract_dir)

                return os.path.join(extract_dir, asset_file)

        except Exception as e:
            logging.error(f"Failed to extract ZIP asset: {e}")
            raise

def add_meshy_asset(
    description: str,
    location: str = "0,0,0",
    scale: float = 1.0,
    api_key: str = None,
    refine: bool = True,
    save_dir: str = "output/meshy_assets",
    filename: str = None,
    blender_path: str = None
) -> dict:
    """
    ä½¿ç”¨ Meshy Text-to-3D ç”Ÿæˆèµ„äº§å¹¶å¯¼å…¥åˆ°å½“å‰åœºæ™¯ï¼ˆç”Ÿæˆâ†’è½®è¯¢â†’ä¸‹è½½â†’å¯¼å…¥ï¼‰

    Args:
        description: æ–‡æœ¬æè¿°ï¼ˆpromptï¼‰
        blender_path: Blender æ–‡ä»¶è·¯å¾„
        location: èµ„äº§ä½ç½® "x,y,z"
        scale: ç¼©æ”¾æ¯”ä¾‹
        api_key: Meshy API å¯†é’¥ï¼ˆå¯é€‰ï¼Œé»˜è®¤è¯» MESHY_API_KEYï¼‰
        refine: æ˜¯å¦åœ¨ preview åè¿›è¡Œ refineï¼ˆå«è´´å›¾ï¼‰
    """
    try:
        # è§£æä½ç½®å‚æ•°
        try:
            loc_parts = [float(x.strip()) for x in location.split(",")]
            if len(loc_parts) != 3:
                return {"status": "error", "error": "Location must be in format 'x,y,z'"}
            asset_location = tuple(loc_parts)
        except Exception:
            return {"status": "error", "error": "Invalid location format. Use 'x,y,z'"}

        # åˆå§‹åŒ– Meshy API
        meshy = MeshyAPI(api_key)

        # 1) åˆ›å»º preview ä»»åŠ¡
        print(f"[Meshy] Creating preview task for: {description}")
        preview_id = meshy.create_text_to_3d_preview(description)

        # 2) è½®è¯¢ preview
        preview_task = meshy.poll_text_to_3d(preview_id, interval_sec=5, timeout_sec=900)
        if preview_task.get("status") != "SUCCEEDED":
            return {"status": "error", "error": f"Preview failed: {preview_task.get('status')}"}
        final_task = preview_task

        # 3) å¯é€‰ refineï¼ˆè´´å›¾ï¼‰
        if refine:
            print(f"[Meshy] Starting refine for preview task: {preview_id}")
            refine_id = meshy.create_text_to_3d_refine(preview_id)
            refine_task = meshy.poll_text_to_3d(refine_id, interval_sec=5, timeout_sec=1800)
            if refine_task.get("status") != "SUCCEEDED":
                return {"status": "error", "error": f"Refine failed: {refine_task.get('status')}"}
            final_task = refine_task

        # 4) ä» model_urls å–ä¸‹è½½é“¾æ¥
        model_urls = (final_task or {}).get("model_urls", {}) or {}
        candidate_keys = ["glb", "fbx", "obj", "zip"]
        file_url = None
        for k in candidate_keys:
            if model_urls.get(k):
                file_url = model_urls[k]
                break
        if not file_url:
            return {"status": "error", "error": "No downloadable model_urls found"}

        # 5) ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°æŒä¹…ç›®å½•
        os.makedirs(save_dir, exist_ok=True)
        # å¤„ç†æ— æ‰©å±•åç›´é“¾ï¼šé»˜è®¤ .glb
        guessed_ext = os.path.splitext(file_url.split("?")[0])[1].lower()
        if guessed_ext not in [".glb", ".gltf", ".fbx", ".obj", ".zip"]:
            guessed_ext = ".glb"
        safe_desc = re.sub(r"[^a-zA-Z0-9_-]+", "_", description)[:60] or "asset"
        base_name = filename or f"text_{safe_desc}_{int(time.time())}"
        local_path = os.path.join(save_dir, f"{base_name}{guessed_ext}")
        print(f"[Meshy] Downloading model to: {local_path}")
        meshy.download_model_url(file_url, local_path)

        # 6) è‹¥ä¸º ZIPï¼Œè§£å‹å‡º 3D æ–‡ä»¶åˆ°ä¿å­˜ç›®å½•ä¸‹çš„åŒåå­ç›®å½•
        if blender_path:
            importer = AssetImporter(blender_path)
            if local_path.endswith(".zip"):
                extract_subdir = os.path.join(save_dir, base_name)
                os.makedirs(extract_subdir, exist_ok=True)
                extracted = importer.extract_zip_asset(local_path, extract_subdir)
                import_path = extracted
            else:
                import_path = local_path

            # 7) å¯¼å…¥ Blender
            imported_object_name = importer.import_asset(import_path, location=asset_location, scale=scale)
            print(f"[Meshy] Imported object: {imported_object_name}")

            # 8) ä¿å­˜ Blender æ–‡ä»¶
            try:
                bpy.ops.wm.save_mainfile(filepath=blender_path)
                print(f"Blender file saved to: {blender_path}")
                
                # æ¸…ç†å¤‡ä»½æ–‡ä»¶ä»¥é¿å…ç”Ÿæˆ .blend1 æ–‡ä»¶
                backup_file = blender_path + "1"
                if os.path.exists(backup_file):
                    os.remove(backup_file)
                    print(f"Removed backup file: {backup_file}")
                    
            except Exception as save_error:
                print(f"Warning: Failed to save blender file: {save_error}")

        return {
            "status": "success",
            "message": "Meshy Text-to-3D asset generated and imported",
            "asset_name": description,
            "object_name": imported_object_name,
            "location": asset_location,
            "scale": scale,
            "saved_model_path": import_path
        }

    except Exception as e:
        logging.error(f"Failed to add Meshy asset: {e}")
        return {"status": "error", "error": str(e)}

def add_meshy_asset_from_image(
    image_path: str,
    location: str = "0,0,0",
    scale: float = 1.0,
    prompt: str = None,
    api_key: str = None,
    refine: bool = True,
    save_dir: str = "output/meshy_assets",
    filename: str = None,
    blender_path: str = None,
) -> dict:
    """
    ä½¿ç”¨ Meshy Image-to-3D æ ¹æ®è¾“å…¥å›¾ç‰‡ç”Ÿæˆèµ„äº§å¹¶å¯¼å…¥åˆ°å½“å‰åœºæ™¯ï¼ˆç”Ÿæˆâ†’è½®è¯¢â†’ä¸‹è½½â†’å¯¼å…¥ï¼‰

    Args:
        image_path: è¾“å…¥å›¾ç‰‡è·¯å¾„
        blender_path: Blender æ–‡ä»¶è·¯å¾„
        location: èµ„äº§ä½ç½® "x,y,z"
        scale: ç¼©æ”¾æ¯”ä¾‹
        prompt: å¯é€‰çš„æ–‡æœ¬æç¤ºï¼Œç”¨äºæŒ‡å¯¼ç”Ÿæˆ
        api_key: Meshy API å¯†é’¥ï¼ˆå¯é€‰ï¼Œé»˜è®¤è¯» MESHY_API_KEYï¼‰
        refine: æ˜¯å¦åœ¨ preview åè¿›è¡Œ refineï¼ˆå«è´´å›¾ï¼‰
    """
    try:
        # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(image_path):
            return {"status": "error", "error": f"Image file not found: {image_path}"}
        
        # è§£æä½ç½®å‚æ•°
        try:
            loc_parts = [float(x.strip()) for x in location.split(",")]
            if len(loc_parts) != 3:
                return {"status": "error", "error": "Location must be in format 'x,y,z'"}
            asset_location = tuple(loc_parts)
        except Exception:
            return {"status": "error", "error": "Invalid location format. Use 'x,y,z'"}

        # åˆå§‹åŒ– Meshy API
        meshy = MeshyAPI(api_key)

        # 1) åˆ›å»º Image-to-3D preview ä»»åŠ¡
        print(f"[Meshy] Creating Image-to-3D preview task for: {image_path}")
        if prompt:
            print(f"[Meshy] Using prompt: {prompt}")
        
        preview_id = meshy.create_image_to_3d_preview(image_path, prompt)

        # 2) è½®è¯¢ preview
        preview_task = meshy.poll_image_to_3d(preview_id, interval_sec=5, timeout_sec=900)
        if preview_task.get("status") != "SUCCEEDED":
            return {"status": "error", "error": f"Image-to-3D preview failed: {preview_task.get('status')}"}
        final_task = preview_task

        # 3) å¯é€‰ refineï¼ˆè´´å›¾ï¼‰
        if refine:
            print(f"[Meshy] Starting refine for Image-to-3D preview task: {preview_id}")
            refine_id = meshy.create_image_to_3d_refine(preview_id)
            refine_task = meshy.poll_image_to_3d(refine_id, interval_sec=5, timeout_sec=1800)
            if refine_task.get("status") != "SUCCEEDED":
                return {"status": "error", "error": f"Image-to-3D refine failed: {refine_task.get('status')}"}
            final_task = refine_task

        # 4) ä» model_urls å–ä¸‹è½½é“¾æ¥
        model_urls = (final_task or {}).get("model_urls", {}) or {}
        candidate_keys = ["glb", "fbx", "obj", "zip"]
        file_url = None
        for k in candidate_keys:
            if model_urls.get(k):
                file_url = model_urls[k]
                break
        if not file_url:
            return {"status": "error", "error": "No downloadable model_urls found"}

        # 5) ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°æŒä¹…ç›®å½•
        os.makedirs(save_dir, exist_ok=True)
        # å¤„ç†æ— æ‰©å±•åç›´é“¾ï¼šé»˜è®¤ .glb
        guessed_ext = os.path.splitext(file_url.split("?")[0])[1].lower()
        if guessed_ext not in [".glb", ".gltf", ".fbx", ".obj", ".zip"]:
            guessed_ext = ".glb"
        safe_source = re.sub(r"[^a-zA-Z0-9_-]+", "_", os.path.splitext(os.path.basename(image_path))[0])[:60] or "image"
        base_name = filename or f"image_{safe_source}_{int(time.time())}"
        local_path = os.path.join(save_dir, f"{base_name}{guessed_ext}")
        print(f"[Meshy] Downloading Image-to-3D model to: {local_path}")
        meshy.download_model_url(file_url, local_path)

        # 6) è‹¥ä¸º ZIPï¼Œè§£å‹å‡º 3D æ–‡ä»¶åˆ°ä¿å­˜ç›®å½•ä¸‹çš„åŒåå­ç›®å½•
        if blender_path:
            importer = AssetImporter(blender_path)
            if local_path.endswith(".zip"):
                extract_subdir = os.path.join(save_dir, base_name)
                os.makedirs(extract_subdir, exist_ok=True)
                extracted = importer.extract_zip_asset(local_path, extract_subdir)
                import_path = extracted
            else:
                import_path = local_path

            # 7) å¯¼å…¥ Blender
            imported_object_name = importer.import_asset(import_path, location=asset_location, scale=scale)
            print(f"[Meshy] Imported Image-to-3D object: {imported_object_name}")

            # 8) ä¿å­˜ Blender æ–‡ä»¶
            try:
                bpy.ops.wm.save_mainfile(filepath=blender_path)
                print(f"Blender file saved to: {blender_path}")
                
                # æ¸…ç†å¤‡ä»½æ–‡ä»¶ä»¥é¿å…ç”Ÿæˆ .blend1 æ–‡ä»¶
                backup_file = blender_path + "1"
                if os.path.exists(backup_file):
                    os.remove(backup_file)
                    print(f"Removed backup file: {backup_file}")
                    
            except Exception as save_error:
                print(f"Warning: Failed to save blender file: {save_error}")

        return {
            "status": "success",
            "message": "Meshy Image-to-3D asset generated and imported",
            "image_path": image_path,
            "prompt": prompt,
            "object_name": imported_object_name,
            "location": asset_location,
            "scale": scale,
            "saved_model_path": local_path
        }
        
    except Exception as e:
        logging.error(f"Failed to add Meshy asset from image: {e}")
        return {"status": "error", "error": str(e)}

def crop_image_by_text(
    image_path: str,
    description: str,
    output_path: str = None,
    confidence_threshold: float = 0.5,
    padding: int = 20
) -> dict:
    """
    æ ¹æ®æ–‡æœ¬æè¿°ä»å›¾ç‰‡ä¸­æˆªå–ç›¸å…³åŒºåŸŸï¼ˆç±»ä¼¼ç‰©ä½“æ£€æµ‹ï¼‰
    
    Args:
        image_path: è¾“å…¥å›¾ç‰‡è·¯å¾„
        description: æ–‡æœ¬æè¿°ï¼Œæè¿°è¦æˆªå–çš„å¯¹è±¡ï¼ˆå¦‚ï¼š"person", "car", "dog", "building"ç­‰ï¼‰
        output_path: è¾“å‡ºå›¾ç‰‡è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰
        confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆ0.0-1.0ï¼‰ï¼Œé»˜è®¤0.5
        padding: æˆªå–åŒºåŸŸå‘¨å›´çš„å¡«å……åƒç´ ï¼Œé»˜è®¤20åƒç´ 
        
    Returns:
        dict: åŒ…å«æˆªå–ç»“æœçš„å­—å…¸ï¼Œæ ¼å¼ä¸ºï¼š
        {
            "status": "success/error",
            "message": "æ“ä½œç»“æœæè¿°",
            "input_image": "è¾“å…¥å›¾ç‰‡è·¯å¾„",
            "output_image": "è¾“å‡ºå›¾ç‰‡è·¯å¾„",
            "detected_object": {
                "description": "æ£€æµ‹åˆ°çš„å¯¹è±¡ç±»åˆ«",
                "confidence": ç½®ä¿¡åº¦,
                "bbox": [x, y, width, height],
                "original_bbox": [åŸå§‹è¾¹ç•Œæ¡†]
            },
            "crop_info": {
                "original_size": [åŸå§‹å›¾ç‰‡å°ºå¯¸],
                "cropped_size": [æˆªå–åå°ºå¯¸],
                "padding": å¡«å……åƒç´ 
            }
        }
    """
    try:
        # åˆ›å»ºå›¾ç‰‡æˆªå–å™¨å®ä¾‹
        cropper = ImageCropper()
        
        # æ‰§è¡Œæˆªå–æ“ä½œ
        result = cropper.crop_image_by_text(
            image_path=image_path,
            description=description,
            output_path=output_path,
            confidence_threshold=confidence_threshold,
            padding=padding
        )
        
        return result
        
    except Exception as e:
        logging.error(f"Failed to crop image by text: {e}")
        return {"status": "error", "error": str(e)}

def crop_and_generate_3d_asset(
    image_path: str,
    description: str,
    blender_path: str,
    location: str = "0,0,0",
    scale: float = 1.0,
    prompt: str = None,
    api_key: str = None,
    refine: bool = True,
    confidence_threshold: float = 0.5,
    padding: int = 20
) -> dict:
    """
    ç»“åˆå›¾ç‰‡æˆªå–å’Œ3Dèµ„äº§ç”Ÿæˆçš„å·¥å…·ï¼š
    1. æ ¹æ®æ–‡æœ¬æè¿°ä»å›¾ç‰‡ä¸­æˆªå–ç›¸å…³åŒºåŸŸ
    2. å°†æˆªå–çš„å›¾ç‰‡é€å…¥Meshyç”Ÿæˆ3Dèµ„äº§
    3. å¯¼å…¥åˆ°Blenderåœºæ™¯ä¸­
    
    Args:
        image_path: è¾“å…¥å›¾ç‰‡è·¯å¾„
        description: æ–‡æœ¬æè¿°ï¼Œæè¿°è¦æˆªå–çš„å¯¹è±¡ï¼ˆå¦‚ï¼š"person", "car", "dog", "building"ç­‰ï¼‰
        blender_path: Blenderæ–‡ä»¶è·¯å¾„
        location: èµ„äº§ä½ç½® "x,y,z"ï¼Œé»˜è®¤ä¸º "0,0,0"
        scale: ç¼©æ”¾æ¯”ä¾‹ï¼Œé»˜è®¤ä¸º 1.0
        prompt: å¯é€‰çš„æ–‡æœ¬æç¤ºï¼Œç”¨äºæŒ‡å¯¼3Dç”Ÿæˆ
        api_key: Meshy APIå¯†é’¥ï¼ˆå¯é€‰ï¼Œé»˜è®¤è¯»MESHY_API_KEYç¯å¢ƒå˜é‡ï¼‰
        refine: æ˜¯å¦è¿›è¡Œrefineå¤„ç†ï¼ˆå«è´´å›¾ï¼‰ï¼Œé»˜è®¤ä¸ºTrue
        confidence_threshold: æˆªå–æ—¶çš„ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆ0.0-1.0ï¼‰ï¼Œé»˜è®¤0.5
        padding: æˆªå–åŒºåŸŸå‘¨å›´çš„å¡«å……åƒç´ ï¼Œé»˜è®¤20åƒç´ 
        
    Returns:
        dict: åŒ…å«å®Œæ•´æ“ä½œç»“æœçš„å­—å…¸ï¼Œæ ¼å¼ä¸ºï¼š
        {
            "status": "success/error",
            "message": "æ“ä½œç»“æœæè¿°",
            "crop_result": {
                "input_image": "è¾“å…¥å›¾ç‰‡è·¯å¾„",
                "cropped_image": "æˆªå–çš„å›¾ç‰‡è·¯å¾„",
                "detected_object": {...}
            },
            "generation_result": {
                "object_name": "å¯¼å…¥çš„å¯¹è±¡åç§°",
                "location": [x, y, z],
                "scale": ç¼©æ”¾æ¯”ä¾‹
            }
        }
    """
    try:
        print(f"[Crop&Generate] Starting combined crop and 3D generation process...")
        print(f"[Crop&Generate] Input image: {image_path}")
        print(f"[Crop&Generate] Description: {description}")
        
        # æ­¥éª¤1: å›¾ç‰‡æˆªå–
        print(f"[Crop&Generate] Step 1: Cropping image based on '{description}'...")
        cropper = ImageCropper()
        
        # ç”Ÿæˆæˆªå–å›¾ç‰‡çš„ä¸´æ—¶è·¯å¾„
        temp_dir = tempfile.mkdtemp(prefix="crop_generate_")
        base_name = os.path.splitext(os.path.basename(image_path))[0]
        cropped_image_path = os.path.join(temp_dir, f"{base_name}_cropped_{description.replace(' ', '_')}.jpg")
        
        crop_result = cropper.crop_image_by_text(
            image_path=image_path,
            description=description,
            output_path=cropped_image_path,
            confidence_threshold=confidence_threshold,
            padding=padding
        )
        
        if crop_result.get("status") != "success":
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            try:
                shutil.rmtree(temp_dir, ignore_errors=True)
            except:
                pass
            return {
                "status": "error",
                "error": f"Image cropping failed: {crop_result.get('error')}",
                "crop_result": crop_result
            }
        
        print(f"[Crop&Generate] âœ“ Image cropped successfully: {cropped_image_path}")
        
        # æ­¥éª¤2: 3Dèµ„äº§ç”Ÿæˆ
        print(f"[Crop&Generate] Step 2: Generating 3D asset from cropped image...")
        
        # å¦‚æœæ²¡æœ‰æä¾›promptï¼Œä½¿ç”¨descriptionä½œä¸ºé»˜è®¤prompt
        if not prompt:
            prompt = f"A 3D model of {description}"
        
        generation_result = add_meshy_asset_from_image(
            image_path=cropped_image_path,
            blender_path=blender_path,
            location=location,
            scale=scale,
            prompt=prompt,
            api_key=api_key,
            refine=refine
        )
        
        if generation_result.get("status") != "success":
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            try:
                shutil.rmtree(temp_dir, ignore_errors=True)
            except:
                pass
            return {
                "status": "error",
                "error": f"3D asset generation failed: {generation_result.get('error')}",
                "crop_result": crop_result,
                "generation_result": generation_result
            }
        
        print(f"[Crop&Generate] âœ“ 3D asset generated and imported successfully")
        
        # æ­¥éª¤3: æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            shutil.rmtree(temp_dir, ignore_errors=True)
            print(f"[Crop&Generate] âœ“ Cleaned up temporary files")
        except Exception as cleanup_error:
            print(f"[Crop&Generate] âš  Warning: Failed to cleanup temp files: {cleanup_error}")
        
        # è¿”å›å®Œæ•´ç»“æœ
        return {
            "status": "success",
            "message": f"Successfully cropped image and generated 3D asset for '{description}'",
            "crop_result": {
                "input_image": image_path,
                "cropped_image": crop_result.get("output_image"),
                "detected_object": crop_result.get("detected_object"),
                "crop_info": crop_result.get("crop_info")
            },
            "generation_result": {
                "object_name": generation_result.get("object_name"),
                "location": generation_result.get("location"),
                "scale": generation_result.get("scale"),
                "prompt": prompt,
                "refine": refine
            },
            "summary": {
                "description": description,
                "original_image": image_path,
                "cropped_image": crop_result.get("output_image"),
                "generated_object": generation_result.get("object_name"),
                "final_location": location,
                "final_scale": scale
            }
        }
        
    except Exception as e:
        logging.error(f"Failed to crop and generate 3D asset: {e}")
        return {"status": "error", "error": str(e)}

def render_scene_for_test(blender_path: str, test_name: str, output_dir: str = "output/test/demo/renders") -> dict:
    """
    ä¸ºæµ‹è¯•æ¸²æŸ“å½“å‰åœºæ™¯
    
    Args:
        blender_path: Blenderæ–‡ä»¶è·¯å¾„
        test_name: æµ‹è¯•åç§°ï¼Œç”¨äºç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        output_dir: è¾“å‡ºç›®å½•
        
    Returns:
        dict: æ¸²æŸ“ç»“æœ
    """
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        # timestamp = int(time.time())
        output_filename = blender_path.split("/")[-1].split(".")[0] + ".png"
        output_path = os.path.join(output_dir, output_filename)
        
        # è®¾ç½®æ¸²æŸ“å‚æ•°
        scene = bpy.context.scene
        scene.render.resolution_x = 1024
        scene.render.resolution_y = 1024
        # scene.render.resolution_percentage = 50  # 50%åˆ†è¾¨ç‡ä»¥åŠ å¿«æ¸²æŸ“é€Ÿåº¦
        scene.render.filepath = output_path
        
        # è®¾ç½®æ¸²æŸ“å¼•æ“ä¸ºCyclesï¼ˆå¦‚æœå¯ç”¨ï¼‰æˆ–Eevee
        if 'CYCLES' in bpy.context.scene.render.engine:
            scene.render.engine = 'CYCLES'
            scene.cycles.samples = 32  # å‡å°‘é‡‡æ ·æ•°ä»¥åŠ å¿«æ¸²æŸ“
        else:
            scene.render.engine = 'BLENDER_EEVEE'
        
        # ç¡®ä¿æœ‰ç›¸æœº
        if not any(obj.type == 'CAMERA' for obj in scene.objects):
            # å¦‚æœæ²¡æœ‰ç›¸æœºï¼Œåˆ›å»ºä¸€ä¸ª
            bpy.ops.object.camera_add(location=(5, -5, 3))
            camera = bpy.context.active_object
            camera.rotation_euler = (1.1, 0, 0.785)  # è®¾ç½®ç›¸æœºè§’åº¦
            scene.camera = camera
            print(f"[Render] Created camera for {test_name}")
            
        # å¦åˆ™ï¼Œè®¾ç½®Camera1ä¸ºæ¸²æŸ“ç›¸æœº
        else:
            scene.camera = bpy.data.objects['Camera1']
        
        # æ¸²æŸ“åœºæ™¯
        print(f"[Render] Rendering scene for {test_name}...")
        bpy.ops.render.render(write_still=True)
        
        print(f"[Render] âœ“ Scene rendered successfully: {output_path}")
        
        return {
            "status": "success",
            "message": f"Scene rendered for {test_name}",
            "output_path": output_path,
            "test_name": test_name
        }
        
    except Exception as e:
        print(f"[Render] âŒ Failed to render scene for {test_name}: {e}")
        return {
            "status": "error",
            "error": str(e),
            "test_name": test_name
        }

def test_meshy_assets() -> dict:
    """
    æµ‹è¯• Meshy èµ„äº§ç”ŸæˆåŠŸèƒ½ï¼š
    1. æµ‹è¯• Text-to-3D èµ„äº§ç”Ÿæˆ
    2. æµ‹è¯• Image-to-3D èµ„äº§ç”Ÿæˆ
    """
    print("ğŸ§ª Testing Meshy Asset Generation Functions...")
    
    # æµ‹è¯•é…ç½®
    test_blender_path = "output/test/demo/old_blender_file.blend"
    test_image_path = "output/test/demo/visprompt1.png"
    
    # ç¡®ä¿æµ‹è¯•ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(test_blender_path), exist_ok=True)
    os.makedirs(os.path.dirname(test_image_path), exist_ok=True)
    
    # åˆ›å»ºæµ‹è¯•ç”¨çš„Blenderæ–‡ä»¶
    try:
        # æ‰“å¼€ç°æœ‰çš„blenderæ–‡ä»¶
        bpy.ops.wm.open_mainfile(filepath=test_blender_path)
        print(f"âœ“ Opened test Blender file: {test_blender_path}")
        
        # æ¸²æŸ“åˆå§‹åœºæ™¯
        print("\nğŸ“¸ Rendering initial scene...")
        initial_render = render_scene_for_test(test_blender_path, "initial_scene")
        if initial_render.get("status") == "success":
            print(f"âœ“ Initial scene rendered: {initial_render.get('output_path')}")
        
    except Exception as e:
        print(f"âš  Warning: Could not open test Blender file: {e}")
        return {"status": "error", "error": f"Failed to open test Blender file: {e}"}
    
    # åˆ›å»ºæµ‹è¯•å›¾ç‰‡ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if not os.path.exists(test_image_path):
        try:
            from PIL import Image, ImageDraw
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾ç‰‡
            img = Image.new('RGB', (400, 300), color='lightblue')
            draw = ImageDraw.Draw(img)
            # ç”»ä¸€ä¸ªç®€å•çš„æˆ¿å­
            draw.rectangle([150, 150, 250, 250], fill='brown', outline='black')
            draw.polygon([(150, 150), (200, 100), (250, 150)], fill='red', outline='black')
            draw.rectangle([180, 180, 220, 220], fill='blue', outline='black')
            img.save(test_image_path)
            print(f"âœ“ Created test image: {test_image_path}")
        except Exception as e:
            print(f"âš  Warning: Could not create test image: {e}")
            return {"status": "error", "error": f"Failed to create test image: {e}"}
    
    test_results = {
        "text_to_3d": {"status": "skipped", "message": "API key not provided"},
        "image_to_3d": {"status": "skipped", "message": "API key not provided"},
        "crop_image": {"status": "skipped", "message": "Test image not available"},
        "crop_and_generate": {"status": "skipped", "message": "API key not provided"}
    }
    
    # # æµ‹è¯•1: Text-to-3D èµ„äº§ç”Ÿæˆ
    # print("\nğŸ“ Testing Text-to-3D Asset Generation...")
    # try:
    #     # æ£€æŸ¥æ˜¯å¦æœ‰APIå¯†é’¥
    #     api_key = os.getenv("MESHY_API_KEY")
    #     if not api_key:
    #         print("âš  Skipping Text-to-3D test: MESHY_API_KEY not set")
    #         test_results["text_to_3d"]["message"] = "MESHY_API_KEY environment variable not set"
    #     else:
    #         print("âœ“ API key found, testing Text-to-3D generation...")
    #         result = add_meshy_asset(
    #             description="A beautiful flower",
    #             blender_path=test_blender_path,
    #             location="2,0,0",
    #             scale=1.0,
    #             api_key=api_key,
    #             refine=True # è·³è¿‡refineä»¥èŠ‚çœæ—¶é—´
    #         )
            
    #         if result.get("status") == "success":
    #             print(f"âœ“ Text-to-3D test successful: {result.get('message')}")
    #             test_results["text_to_3d"] = {
    #                 "status": "success",
    #                 "message": result.get("message"),
    #                 "object_name": result.get("object_name")
    #             }
                
    #             # æ¸²æŸ“åœºæ™¯ä»¥æŸ¥çœ‹æ·»åŠ çš„ç‰©ä½“
    #             render_result = render_scene_for_test(test_blender_path, "text_to_3d")
    #             if render_result.get("status") == "success":
    #                 test_results["text_to_3d"]["render_path"] = render_result.get("output_path")
    #                 print(f"âœ“ Rendered scene after Text-to-3D: {render_result.get('output_path')}")
    #         else:
    #             print(f"âŒ Text-to-3D test failed: {result.get('error')}")
    #             test_results["text_to_3d"] = {
    #                 "status": "failed",
    #                 "message": result.get("error")
    #             }
    # except Exception as e:
    #     print(f"âŒ Text-to-3D test error: {e}")
    #     test_results["text_to_3d"] = {
    #         "status": "error",
    #         "message": str(e)
    #     }
    
    # # æµ‹è¯•2: Image-to-3D èµ„äº§ç”Ÿæˆ
    # print("\nğŸ–¼ï¸ Testing Image-to-3D Asset Generation...")
    # try:
    #     api_key = os.getenv("MESHY_API_KEY")
    #     if not api_key:
    #         print("âš  Skipping Image-to-3D test: MESHY_API_KEY not set")
    #         test_results["image_to_3d"]["message"] = "MESHY_API_KEY environment variable not set"
    #     else:
    #         print("âœ“ API key found, testing Image-to-3D generation...")
    #         result = add_meshy_asset_from_image(
    #             image_path=test_image_path,
    #             blender_path=test_blender_path,
    #             location="-2,0,0",
    #             scale=1.0,
    #             prompt="A 3D model of a house",
    #             api_key=api_key,
    #             refine=False  # è·³è¿‡refineä»¥èŠ‚çœæ—¶é—´
    #         )
            
    #         if result.get("status") == "success":
    #             print(f"âœ“ Image-to-3D test successful: {result.get('message')}")
    #             test_results["image_to_3d"] = {
    #                 "status": "success",
    #                 "message": result.get("message"),
    #                 "object_name": result.get("object_name")
    #             }
                
    #             # æ¸²æŸ“åœºæ™¯ä»¥æŸ¥çœ‹æ·»åŠ çš„ç‰©ä½“
    #             render_result = render_scene_for_test(test_blender_path, "image_to_3d")
    #             if render_result.get("status") == "success":
    #                 test_results["image_to_3d"]["render_path"] = render_result.get("output_path")
    #                 print(f"âœ“ Rendered scene after Image-to-3D: {render_result.get('output_path')}")
    #         else:
    #             print(f"âŒ Image-to-3D test failed: {result.get('error')}")
    #             test_results["image_to_3d"] = {
    #                 "status": "failed",
    #                 "message": result.get("error")
    #             }
    # except Exception as e:
    #     print(f"âŒ Image-to-3D test error: {e}")
    #     test_results["image_to_3d"] = {
    #         "status": "error",
    #         "message": str(e)
    #     }
    
    # æµ‹è¯•3: å›¾ç‰‡æˆªå–åŠŸèƒ½
    print("\nâœ‚ï¸ Testing Image Cropping...")
    try:
        if not os.path.exists(test_image_path):
            print("âš  Skipping crop test: Test image not available")
            test_results["crop_image"]["message"] = "Test image not available"
        else:
            print("âœ“ Testing image cropping...")
            result = crop_image_by_text(
                image_path=test_image_path,
                description="coffee cup",
                output_path="test_output/cropped_building.jpg",
                confidence_threshold=0.3,
                padding=10
            )
            
            if result.get("status") == "success":
                print(f"âœ“ Image cropping test successful: {result.get('message')}")
                test_results["crop_image"] = {
                    "status": "success",
                    "message": result.get("message"),
                    "output_image": result.get("output_image")
                }
            else:
                print(f"âŒ Image cropping test failed: {result.get('error')}")
                test_results["crop_image"] = {
                    "status": "failed",
                    "message": result.get("error")
                }
    except Exception as e:
        print(f"âŒ Image cropping test error: {e}")
        test_results["crop_image"] = {
            "status": "error",
            "message": str(e)
        }
    
    # æµ‹è¯•4: ç»„åˆå·¥å…· - å›¾ç‰‡æˆªå– + 3Dèµ„äº§ç”Ÿæˆ
    print("\nğŸ”„ Testing Combined Crop and Generate Tool...")
    try:
        api_key = os.getenv("MESHY_API_KEY")
        if not api_key:
            print("âš  Skipping combined test: MESHY_API_KEY not set")
            test_results["crop_and_generate"]["message"] = "MESHY_API_KEY environment variable not set"
        elif not os.path.exists(test_image_path):
            print("âš  Skipping combined test: Test image not available")
            test_results["crop_and_generate"]["message"] = "Test image not available"
        else:
            print("âœ“ Testing combined crop and generate...")
            result = crop_and_generate_3d_asset(
                image_path=test_image_path,
                description="coffee cup",
                blender_path=test_blender_path,
                location="4,0,0",
                scale=1.0,
                prompt="A detailed 3D model of a house with realistic textures",
                api_key=api_key,
                refine=False,  # è·³è¿‡refineä»¥èŠ‚çœæ—¶é—´
                confidence_threshold=0.3,
                padding=15
            )
            
            if result.get("status") == "success":
                print(f"âœ“ Combined test successful: {result.get('message')}")
                test_results["crop_and_generate"] = {
            "status": "success",
                    "message": result.get("message"),
                    "crop_result": result.get("crop_result"),
                    "generation_result": result.get("generation_result")
                }
                
                # æ¸²æŸ“åœºæ™¯ä»¥æŸ¥çœ‹æ·»åŠ çš„ç‰©ä½“
                render_result = render_scene_for_test(test_blender_path, "crop_and_generate")
                if render_result.get("status") == "success":
                    test_results["crop_and_generate"]["render_path"] = render_result.get("output_path")
                    print(f"âœ“ Rendered scene after Combined test: {render_result.get('output_path')}")
            else:
                print(f"âŒ Combined test failed: {result.get('error')}")
                test_results["crop_and_generate"] = {
                    "status": "failed",
                    "message": result.get("error")
                }
    except Exception as e:
        print(f"âŒ Combined test error: {e}")
        test_results["crop_and_generate"] = {
            "status": "error",
            "message": str(e)
        }
    
    # æ€»ç»“æµ‹è¯•ç»“æœ
    print("\nğŸ“Š Test Results Summary:")
    print("=" * 50)
    
    success_count = 0
    total_tests = 0
    
    for test_name, result in test_results.items():
        total_tests += 1
        status = result["status"]
        message = result["message"]
        
        if status == "success":
            print(f"âœ… {test_name}: SUCCESS - {message}")
            if "render_path" in result:
                print(f"   ğŸ“¸ Render saved: {result['render_path']}")
            success_count += 1
        elif status == "skipped":
            print(f"â­ï¸ {test_name}: SKIPPED - {message}")
        elif status == "failed":
            print(f"âŒ {test_name}: FAILED - {message}")
        else:
            print(f"ğŸ’¥ {test_name}: ERROR - {message}")
    
    print("=" * 50)
    print(f"Tests completed: {success_count}/{total_tests} successful")
    
    # è¿”å›æµ‹è¯•ç»“æœ
    overall_success = success_count > 0 or all(r["status"] == "skipped" for r in test_results.values())
        
    return {
        "status": "success" if overall_success else "failed",
        "message": f"Meshy asset generation tests completed: {success_count}/{total_tests} successful",
        "test_results": test_results,
        "summary": {
            "total_tests": total_tests,
            "successful": success_count,
            "skipped": sum(1 for r in test_results.values() if r["status"] == "skipped"),
            "failed": sum(1 for r in test_results.values() if r["status"] in ["failed", "error"])
        }
    }
